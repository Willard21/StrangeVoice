<!DOCTYPE html>
<html lang="en">
	<meta charset="UTF-8">
	<title>Simple Recorder.js demo with record, stop and pause</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<div id="controls">
		<button id="recordLow">Record Low</button>
	</div>
	<div id="controls">
		<button id="recordHigh">Record High</button>
	</div>
	<div id="controls">
		<button id="classify">Classify Voice</button>
	</div>
	<h3>Recordings</h3>
	<ol id="recordingsList"></ol>
	<!-- inserting these scripts at the end to be able to use all the elements in the DOM --> 
	<script src="https://cdn.rawgit.com/mattdiamond/Recorderjs/08e7abd9/dist/recorder.js"></script>
	<script>
		//webkitURL is deprecated but nevertheless 
		URL = window.URL || window.webkitURL;
		var gumStream;
		//stream from getUserMedia() 
		var rec;
		var audios = [0, 0];
		//Recorder.js object 
		var input;
		var currentRecording = -1;
		var count = 30;

		var recordLow = document.getElementById("recordLow");
		var recordHigh = document.getElementById("recordHigh");
		var classify = document.getElementById("classify");

		
		//add events to those 3 buttons 
		recordLow.addEventListener("click", recordLowPitch);
		recordHigh.addEventListener("click", recordHighPitch);
		classify.addEventListener("click", function(event) {
			var xhr = new XMLHttpRequest();
			xhr.onload = function(e) {
				if (this.readyState === 4) {
					console.log("Server returned: ", e.target.responseText);
				}
			};
			var fd = new FormData();
			audios.forEach((audio, i) => fd.append(`audio${i + 1}`, audio, i < count ? "lowKey" : "highKey"))
			console.log("Data to sent:");
			xhr.open("POST", "/mmm", true);
			xhr.send(fd);
		});

		function recordLowPitch() {
			currentRecording = 0;
			startRecording();
		}
		
		function recordHighPitch() {
			currentRecording = count;
			startRecording();
		}
		
		function startRecording(){
			//MediaStreamAudioSourceNode we'll be recording 
			// shim for AudioContext when it's not avb. 
			var AudioContext = window.AudioContext || window.webkitAudioContext;
			var audioContext = new AudioContext;
			//new audio context to help us record 
			
			/* Disable the record button until we get a success or fail from getUserMedia() */

			/* We're using the standard promise based getUserMedia()

			https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia */
			navigator.mediaDevices.getUserMedia(constraints).then(function(stream) {
				console.log("getUserMedia() success, stream created, initializing Recorder.js ..."); 
				/* assign to gumStream for later use */
				gumStream = stream;
				/* use the stream */
				input = audioContext.createMediaStreamSource(stream);
				/* Create the Recorder object and configure to record mono sound (1 channel) Recording 2 channels will double the file size */
				rec = new Recorder(input, {
					numChannels: 1
				}) 
				//start the recording process 
				rec.record()
				console.log("Recording started");
				window.setTimeout(stopRecording, 100, rec);
			}).catch(function(err) {
				console.log(err)
			});
		}
		
		var constraints = {
			audio: true,
			video: false
		} 

		function stopRecording(rec) {
			console.log("stopButton clicked");
			//reset button just in case the recording is stopped while paused 
			//tell the recorder to stop the recording 
			rec.stop(); //stop microphone access 
			gumStream.getAudioTracks()[0].stop();
			//create the wav blob and pass it on to createDownloadLink 
			rec.exportWAV(saveAudio);
		}
		function saveAudio(blob) {
			if(currentRecording != -1){
				audios[currentRecording++] = blob;
				console.log("Saving: " + currentRecording);
				if (currentRecording % count) {
					startRecording()
				}
			}
		}
		

	</script>
</html>

Object.values({a: "value"}) // returns ["value"]